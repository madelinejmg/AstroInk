import streamlit as st
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from summarizer import summarize_text
from arxiv_scraper import search_arxiv
from keywords import extract_keywords

st.set_page_config(page_title='AstroInk', layout='wide')

st.markdown("""
    <style>
    .main {
        background-color: #f8f9fa;
    }
    h1 {
        text-align: center;
        color: #343a40;
    }
    p {
        text-align: center;
        font-size: 1.2em;
    }
    footer {
        text-align: center;
        font-size: 0.8em;
        color: #6c757d;
        padding-top: 10px;
    }
    </style>
""", unsafe_allow_html=True)

st.title("AstroInk")
st.markdown("**A faster way to search for astrophysical research papers from arXiv..**")

"""
[![](https://github.com/madelinejmg/AstroInk)]
"""

# Sidebar controls
st.sidebar.title("Search Options")
query = st.sidebar.text_input("Enter a topic or keyword:", "M-dwarf exoplanets")
max_results = st.sidebar.slider("Number of Papers", 1, 10, 3)
summary_length = st.sidebar.selectbox("Summary Length", ["Short", "Medium", "Long"], index=1)
length_map = {"Short": 2, "Medium": 4, "Long": 6}

# Sidebar Filter Options
st.sidebar.title("Filter Options")
year_filter = st.sidebar.number_input("Only show papers from year (or later):", value=2020, min_value=1990, max_value=2030)
min_abstract_length = st.sidebar.slider("Minimum Abstract Length (words):", 0, 500, 50)

# About Section
st.sidebar.title("About AstroInk")
st.sidebar.info(
    """
    AstroInk helps users quickly search for, summarize, and cite astrophysical research papers from arXiv.
    Summaries are generated by extracting the first few sentences of each abstract for speed and stability.
    """
)

# --- Main Search Execution ---
if st.sidebar.button("Search"):
    with st.spinner("Searching arXiv..."):
        papers = search_arxiv(query, max_results=max_results)

    if not papers:
        st.warning("No results found. Try a different topic!")
    else:
        st.success(f"Found {len(filtered_papers)} papers matching filters for '{query}'")
        
        # Sort papers by most recent
        papers = sorted(papers, key=lambda x: x['published'], reverse=True)
        
        # Filter papers
        filtered_papers = []
        for paper in papers:
            year = paper['published'].year
            abstract_word_count = len(paper['summary'].split())

            if year >= year_filter and abstract_word_count >= min_abstract_length:
                filtered_papers.append(paper)

    # After filtering papers
    if not filtered_papers:
        st.warning("No papers matched your filters. Try relaxing your filter settings!")
    else:
        # Display papers normally
        summary_texts = []
        # Display papers normally
        for idx, paper in enumerate(filtered_papers):
            st.markdown(f"### {idx+1}. [{paper['title']}]({paper['url']})")

            # BADGES
            col1, col2, col3 = st.columns(3)
        
            abstract_length = len(paper['summary'].split())
            num_authors = len(paper['authors'])
            year_published = paper['published'].year
        
            special_paper = False
            if year_published >= 2024 and abstract_length > 250:
                special_paper = True
        
            with col1:
                if year_published >= 2024:
                    st.badge("New", color="blue")
            with col2:
                if num_authors > 5:
                    st.badge("Big Collaboration", color="purple")
            with col3:
                if abstract_length > 250:
                    st.badge("Detailed", color="green")
                elif abstract_length < 100: 
                    st.badge("Short Abstract", color="red")

            st.markdown(f"**Authors:** {', '.join(paper['authors'])}")
            st.markdown(f"**Published:** {paper['published'].date()}")

            # Extract and show keywords
            keywords = extract_keywords(paper['summary'])
            st.markdown("**Keywords:** " + ", ".join(f"`{kw}`" for kw in keywords))
            
            #max_len, min_len = (150, 30)  # If you are still using simple regex summarization
            summary = summarize_text(paper['summary'], num_sentences=length_map[summary_length])

            # Summary
            st.markdown("**Summary:**")
            st.write(summary)
            st.caption("Note: Summaries are based on the first few sentences for fast performance.")
            
            summary_texts.append(f"Title: {paper['title']}\nSummary: {summary}\n")

            # Citation block
            st.markdown("**Citation (BibTeX):**")
            st.code(paper['citation'], language='bibtex')

            # Individual BibTeX download
            st.download_button(
                label="Download BibTeX",
                data=paper['citation'],
                file_name=f"{paper['title'][:50].replace(' ', '_')}.bib",
                mime="text/plain"
            )
            
            # PDF Download link
            paper_id = paper['url'].split('/')[-1]  # Get the arXiv ID part
            pdf_url = f"https://arxiv.org/pdf/{paper_id}.pdf"
            st.markdown(f"[Download PDF]({pdf_url})", unsafe_allow_html=True)

            st.markdown("---")
            
        # Export all summaries
        if summary_texts:
            full_export = "\n\n".join(summary_texts)
            st.sidebar.download_button(
                label="Download All Summaries",
                data=full_export,
                file_name="astroink_summaries.txt",
                mime="text/plain"
            )
            
        # Export all citations
        if filtered_papers:
            all_citations = "\n\n".join(paper['citation'] for paper in filtered_papers)
            st.sidebar.download_button(
                label="Download All Citations (.bib)",
                data=all_citations,
                file_name="astroink_citations.bib",
                mime="text/plain"
            )
